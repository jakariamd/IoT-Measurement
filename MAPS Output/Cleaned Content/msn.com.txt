For nearly two decades, Twitter has reigned as the leader in the microblogging space, but it now appears to be facing real competition from Threads, which has seen rapid growth. But media reports about Threads violating users' privacy have raised concerns. What is the real truth, though? Is Threads genuinely worse than Twitter when it comes to privacy and cybersecurity, or is it simply facing more scrutiny due to being owned by a company that does not have a great reputation? Twitter and Privacy: What You Need to Know Let's begin with Twitter. For a start, Twitter has a fairly straightforward, interactive, and easy-to-read privacy policy . This is praiseworthy, because many companies nowadays seem to deliberately obscure their privacy policies, employing a lot of legalese and making it nearly impossible for the average person to comprehend how much data they are being asked to surrender. But content is more important than presentation. How much data does Twitter collect? To begin with, the data Twitter collects from users can be split into three distinct categories: information users themselves provide, information that is gathered from them, and information obtained from third parties. In order to create an account on Twitter in the first place, you are required to provide some personal information. You need to create a display name and set up a password, and verify your account using your email or phone number. You also have to share your date of birth, and can choose whether to share location information . Professional accounts might need to provide additional info, while those who purchase ads and other services obviously need to share payment info as well. When it comes to data that is being gathered from users about their activity, the list is too long. But let's say that pretty much everything you do on Twitter is recorded and stored: your retweets, likes, direct messages (including the contents of the message), replies, mentions, interactions with links posted on the platform, and so on. Twitter also gathers a lot of technical data, such as information about your IP address and browser, device, and operating system. Notably, Twitter also states in its privacy policy that it collects information that can be used to "infer your identity." That's to say, even if you are not logged into your account when browsing Twitter, the platform will try to make an educated guess about who you are, and connect the information it gathered to the data it had already stored about you. In most privacy policies, the term "third parties" is pretty broad. In Twitter's case, it refers to advertising partners, publishers, developers, other Twitter users, affiliates, and partners. These also collect information about you, and share it with Twitter. So, for example, if you connect your account with another service or app, that entity might share the data it gathers with Twitter. Lastly, there are things you can do to enhance your privacy on Twitter , but your options are limited. What Does Threads Know About You? To really understand how much data Threads collects, we need to look at two privacy policies: the one that applies to most Meta Platforms' products, and the Threads Supplemental Privacy Policy. As a reminder, Meta also owns and operates Facebook and Instagram, among other products and services. In its rather exhaustive privacy policy , the company breaks down how much data it gathers, how, and for what purposes. It would be impossible to cover every detail in a brief summary, but suffice to say that Meta knows just about everything that it realistically can know about those who use its products and services. Even those who don't are not exempt from this, because Meta acknowledges it may "collect some information about you even if you don't have an account." It goes without saying that Meta products track your IP address , but the company also gathers other information about your device, operating system, and about how you use Meta apps. Meta knows if your mouse is moving, collects info about your network connection, knows your location (even if Location Services are turned off), and may have access to your camera and photos. Meta apps don't just gather data about you, but also about your friends, followers, and contacts. For example, if you sync the address book on your phone with a Meta app, the tech giant automatically collects information about your contacts. It further stores all kinds of data about your posts (including metadata), messages, and other content that you share and upload to its platforms. Meta also receives info about you from various third parties, which includes marketing vendors, partners, and other affiliates. So, for instance, the company may learn about the games you play and websites you visit through social plugins and pixels. It also records how you interact with advertisements, and may even get data about your demographics.The Threads Supplemental Privacy Policy is a lot shorter, but it does contain some valuable insights. It says that all data gathered via Threads is cross-referenced with information Meta already has about you, provided that you use other Meta products—and you can't use Threads without creating an account on Instagram. The same document states that you cannot delete your Threads account without deleting Instagram, which is definitely something to keep in mind. You can deactivate it, however, just like you can request a deletion of your Threads information through Instagram settings . It's also worth noting that the extent of data gathering, as well as your rights in the online space, may vary depending on the country or region you are from. Is Threads More Private Than Twitter? After taking a careful look at how Twitter and Threads treat their users, the real question is: which of these two apps is better for your privacy? The real answer, then, is neither. But if you had to use one, it appears as though Twitter is slightly less invasive. This might change in the near future, and it's difficult to tell where Elon Musk is taking Twitter, but if you actually want to guard your data from big tech while participating in online discussions, you should consider joining other platforms. Continue reading USA TODAYUSA TODAYPeopleThe Jerusalem Post More for You FeedbackHave you ever Googled yourself? You may be surprised at what you find. Searching your name online is no longer a novelty or a lark. In fact, it can be a crucial part of managing your online reputation at a time when an ill-judged tweet or inappropriate photo can cost you your livelihood. If you do come across personal — or even sensitive — content about yourself in a web search, don’t panic. Google can wipe any unwanted personal info that others have uploaded. This can include bank account details, your home address, phone number, and explicit photos. Whereas you currently have to scour the web for these undesirable results yourself, and then submit a takedown request form, Google will soon take a more proactive approach to the cleanup process. To make things less cumbersome, the company will release a new dashboard for the Google app that alerts you when your contact info appears in Search. Then, you can quickly request the removal of those results from within the same tool. The update is now available in the US and will come to more countries soon, Google announced on Thursday (August 3). It’s worth bearing in mind that removing info from Google Search doesn’t mean it will completely vanish from the internet or other search engines. According to Google, the change is part of a broader shakeup of its privacy and online safety tools. Going beyond existing takedowns of non-consensual explicit imagery, one of the new features lets users remove explicit content that they uploaded themselves. “For example, if you created and uploaded explicit content to a website, then deleted it, you can request its removal from Search if it’s being published elsewhere without approval,” Google wrote in a blog post . “This policy doesn’t apply to content you are currently commercializing,” it added in a nod to adult video subscription services such as OnlyFans . Google is also going to blur explicit images in search results by default around the world. The company introduced the change earlier this year following pressure from US lawmakers to safeguard families and children from adult or graphic violent content. In addition, the company is making it easier to access parental controls from within search. Instead of rifling through your settings, you can find info on the limits for children by typing a relevant query like “google parental controls” or “google family link”. Register now for one of the Evening Standard’s newsletters. From a daily news briefing to Homes & Property insights, plus lifestyle, going out, offers and more. For the best stories in your inbox, click here . USA TODAYUSA TODAYPeopleBloomberg More for You FeedbackGoogle updated its privacy policy over the weekend, explicitly saying the company reserves the right to scrape just about everything you post online to build its AI tools. If Google can read your words, assume they belong to the company now, and expect that they’re nesting somewhere in the bowels of a chatbot. “Google uses information to improve our services and to develop new products, features and technologies that benefit our users and the public,” the new Google policy says . “For example, we use publicly available information to help train Google’s AI models and build products and features like Google Translate, Bard, and Cloud AI capabilities.” Fortunately for history fans, Google maintains a history of changes to its terms of service. The new language amends an existing policy, spelling out new ways your online musings might be used for the tech giant’s AI tools work. Previously, Google said the data would be used “for language models,” rather than “AI models,” and where the older policy just mentioned Google Translate, Bard and Cloud AI now make an appearance. This is an unusual clause for a privacy policy. Typically, these policies describe ways that a business uses the information that you post on the company’s own services. Here, it seems Google reserves the right to harvest and harness data posted on any part of the public web, as if the whole internet is the company’s own AI playground. Google did not immediately respond to a request for comment. The practice raises new and interesting privacy questions. People generally understand that public posts are public. But today, you need a new mental model of what it means to write something online. It’s no longer a question of who can see the information, but how it could be used. There’s a good chance that Bard and ChatGPT ingested your long forgotten blog posts or 15-year-old restaurant reviews. As you read this, the chatbots could be regurgitating some humonculoid version of your words in ways that are impossible to predict and difficult to understand. One of the less obvious complications of the post ChatGPT world is the question of where data-hungry chatbots sourced their information. Companies including Google and OpenAI scraped vast portions of the internet to fuel their robot habits. It’s not at all clear that this is legal , and the next few years will see the courts wrestle with copyright questions that would have seemed like science fiction a few years ago. In the meantime, the phenomenon already affects consumers in some unexpected ways. The overlords at Twitter and Reddit feel particularly aggrieved about the AI issue, and made controversial changes to lockdown their platforms. Both companies turned off free access to their API’s which allowed anyone who pleased to download large quantities of posts. Ostensibly, that’s meant to protect the social media sites from other companies harvesting their intellectual property, but it’s had other consequences. Twitter and Reddit’s API changes broke third-party tools that many people used to access those sites. For a minute, it even seemed Twitter was going to force public entities such as weather, transit, and emergency services to pay if they wanted to Tweet, a move that the company walked back after a hailstorm of criticism. Lately, web scraping is Elon Musk’s favorite boogieman. Musk blamed a number of recent Twitter disasters on the company’s need to stop others from pulling data off his site, even when the issues seem unrelated. Over the weekend, Twitter limited the number of tweets users were allowed to look at per day, rendering the service almost unusable. Musk said it was a necessary response to “data scraping” and “system manipulation.” However, most IT experts agreed the rate limiting was more likely a crisis response to technical problems born of mismanagement, incompetence, or both. Twitter did not answer Gizmodo’s questions on the subject. On Reddit, the effect of API changes was particularly noisy. Reddit is essentially run by unpaid moderators who keep the forums healthy. Mods of large subreddits tend to rely on third-party tools for their work, tools that are built on now inaccessible APIs. That sparked a mass protest , where moderators essentially shut Reddit down. Though the controversy is still playing out, it’s likely to have permanent consequences as spurned moderators hang up their hats. Sign up for Gizmodo's Newsletter. For the latest news, Facebook , Twitter and Instagram . Continue reading Sponsored Content USA TODAYUSA TODAYPeopleThe Jerusalem Post More for You will remove false information about cancer treatments as part of its efforts to rein in medical misinformation . The video-hosting platform announced an updated and expanded medical misinformation policy on Tuesday, including barring false claims about cancer .The restricted content includes videos that "promote cancer treatments proven to be harmful or ineffective, or content that discourages viewers from seeking professional medical treatment," Dr. Garth Graham, head of YouTube Health, said in a blog post . "This includes content that promotes unproven treatments in place of approved care or as a guaranteed cure, and treatments that have been specifically deemed harmful by health authorities," Graham added. He included the example of "taking vitamin C instead of radiation therapy." The company is also adopting a broader updated medical misinformation policy that will consider content in three categories: prevention, treatment, and denial. "To determine if a condition, treatment, or substance is in the scope of our medical misinformation policies, we'll evaluate whether it's associated with a high public health risk, publicly available guidance from health authorities around the world, and whether it's generally prone to misinformation," Graham wrote. He also noted the platform will act on content that falls into that framework and "contradicts local health authorities or the World Health Organization." YouTube's content moderation policies have been the subject of scrutiny in the wake of its efforts to police claims about the coronavirus during the pandemic. It also announced in July 2022 that it was restricting videos providing information on how to do self-performed abortions. YouTube's decision to rely on sources such as the WHO has led to errors regarding COVID-19. It censored claims about a laboratory in Wuhan being the origin of the COVID-19 virus, a theory now seen as plausible by several government entities. The company also began certifying health professionals who create medical content in October to ensure users knew which doctors were legitimately trained and which were not. Original Author: Christopher Hutton Original Location: YouTube updates health 'misinformation' policy to ban false cancer cures Continue reading More for You Feedback