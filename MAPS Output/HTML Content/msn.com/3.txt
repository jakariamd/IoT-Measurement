<p><p>  Google updated its privacy policy over the weekend, explicitly saying the company reserves the right to scrape just about everything you post online to build its AI tools. If Google can read your words, assume they belong to the company now, and expect that they’re nesting somewhere in the bowels of a chatbot. </p></p> <p><p>  “Google uses information to improve our services and to develop new products, features and technologies that benefit our users and the public,” <a href="https://policies.google.com/privacy" target="_blank"> the new Google policy says </a>. “For example, we use publicly available information to help train Google’s AI models and build products and features like Google Translate, Bard, and Cloud AI capabilities.”</p></p> <p><p>  Fortunately for history fans, Google maintains a <a href="https://policies.google.com/privacy/archive/20221215-20230701" target="_blank"> history of changes </a> to its terms of service. The new language amends an existing policy, spelling out new ways your online musings might be used for the tech giant’s AI tools work.</p></p> <p><p>   Previously, Google said the data would be used “for language models,” rather than “AI models,” and where the older policy just mentioned Google Translate, Bard and Cloud AI now make an appearance.</p></p> <p><p>  This is an unusual clause for a privacy policy. Typically, these policies describe ways that a business uses the information that you post on the company’s own services. Here, it seems Google reserves the right to harvest and harness data posted on any part of the public web, as if the whole internet is the company’s own AI playground. Google did not immediately respond to a request for comment. </p></p> <p><p>   The practice raises new and interesting privacy questions. People generally understand that public posts are public. But today, you need a new mental model of what it means to write something online. It’s no longer a question of who can see the information, but how it could be used. There’s a good chance that Bard and ChatGPT ingested your long forgotten blog posts or 15-year-old restaurant reviews. As you read this, the chatbots could be regurgitating some humonculoid version of your words in ways that are impossible to predict and difficult to understand.</p></p> <p><p>  One of the less obvious complications of the post ChatGPT world is the question of where data-hungry chatbots sourced their information. Companies including Google and <a href="https://gizmodo.com/chatbot-gpt4-open-ai-ai-bing-microsoft-1850229989" target="_blank"> OpenAI scraped vast portions of the internet </a> to fuel their robot habits. <a href="https://gizmodo.com/a-new-class-action-lawsuit-adds-to-openais-growing-lega-1850593431" target="_blank"> It’s not at all clear that this is legal </a>, and the next few years will see the courts wrestle with copyright questions that would have seemed like science fiction a few years ago. In the meantime, the phenomenon already affects consumers in some unexpected ways.</p></p> <p><p>  The overlords at Twitter and Reddit feel particularly aggrieved about the AI issue, and made controversial changes to lockdown their platforms. Both companies turned off free access to their API’s which allowed anyone who pleased to download large quantities of posts. Ostensibly, that’s meant to protect the social media sites from other companies harvesting their intellectual property, but it’s had other consequences. </p></p> <p><p>  Twitter and <a href="https://gizmodo.com/reddit-ceo-steve-huffman-moderators-landed-gentry-1850546737" target="_blank"> Reddit’s API changes broke third-party tools </a> that many people used to access those sites. For a minute, it even seemed Twitter was going to <a href="https://gizmodo.com/twitter-api-public-service-mta-elon-musk-1850398698" target="_blank"> force public entities </a> such as weather, transit, and emergency services to pay if they wanted to Tweet, a move that the company walked back after a hailstorm of criticism. </p></p> <p><p>  Lately, web scraping is Elon Musk’s favorite boogieman. Musk blamed a number of recent Twitter disasters on the company’s need to stop others from pulling data off his site, even when the issues seem unrelated. Over the weekend, <a href="https://gizmodo.com/tweetdeck-falters-as-elon-musk-wrecks-twitter-1850601063" target="_blank"> Twitter limited the number of tweets </a> users were allowed to look at per day, rendering the service almost unusable. Musk said it was a necessary response to “data scraping” and “system manipulation.” However, most IT experts agreed the rate limiting was more likely a crisis response to technical problems born of mismanagement, incompetence, or both. Twitter did not answer Gizmodo’s questions on the subject. </p></p> <p><p>  On Reddit, the effect of API changes was particularly noisy. Reddit is essentially run by unpaid moderators who keep the forums healthy. Mods of large subreddits tend to rely on third-party tools for their work, tools that are built on now inaccessible APIs. That <a href="https://gizmodo.com/subreddits-are-planning-an-indefinite-blackout-in-respo-1850537972" target="_blank"> sparked a mass protest </a>, where moderators essentially shut Reddit down. Though the controversy is still playing out, it’s likely to have <a href="https://gizmodo.com/reddit-threatens-subs-to-go-public-again-traffic-down-1850590583" target="_blank"> permanent consequences </a> as spurned moderators hang up their hats.</p></p> <p><p>  Sign up for <a href="http://gizmodo.com/newsletter" target="_blank"> Gizmodo's Newsletter. </a> For the latest news, <a href="https://www.facebook.com/gizmodo" target="_blank"> Facebook </a>, <a href="https://twitter.com/gizmodo" target="_blank"> Twitter </a> and <a href="https://instagram.com/gizmodo" target="_blank"> Instagram </a>.</p></p> <div><span>  Continue reading</span><span>  Sponsored Content</span><ul>  <li>USA TODAY</li><li>USA TODAY</li><li>People</li><li>The Jerusalem Post</li></ul></div> <div><h2>  More for You</h2><span>  will remove false information about cancer treatments as part of its efforts to rein in <a href="https://www.washingtonexaminer.com/tag/misinformation" target="_blank"> medical misinformation </a>. </span><p>  The video-hosting platform announced an updated and expanded medical misinformation policy on Tuesday, including barring false claims about <a href="https://www.washingtonexaminer.com/tag/cancer" target="_blank"> cancer </a>. </p><p>  The restricted content includes videos that "promote cancer treatments proven to be harmful or ineffective, or content that discourages viewers from seeking professional medical treatment," Dr. Garth Graham, head of YouTube Health, said in a <a href="https://blog.youtube/inside-youtube/a-long-term-vision-for-medical-misinformation-policies/" target="_blank"> blog post </a>. </p></div> <p><p>  "This includes content that promotes unproven treatments in place of approved care or as a guaranteed cure, and treatments that have been specifically deemed harmful by health authorities," Graham added. He included the example of "taking vitamin C instead of radiation therapy." </p></p> <p><p>  The company is also adopting a broader updated medical misinformation policy that will consider content in three categories: prevention, treatment, and denial.  </p></p> <p><p>  "To determine if a condition, treatment, or substance is in the scope of our medical misinformation policies, we'll evaluate whether it's associated with a high public health risk, publicly available guidance from health authorities around the world, and whether it's generally prone to misinformation," Graham wrote. He also noted the platform will act on content that falls into that framework and "contradicts local health authorities or the World Health Organization." </p></p> <p><p>  YouTube's content moderation policies have been the subject of scrutiny in the wake of its efforts to police claims about the coronavirus during the pandemic. It also <a href="https://www.washingtonexaminer.com/news/youtube-abortion-misinformation-unsafe-procedures" target="_blank"> announced </a> in July 2022 that it was restricting videos providing information on how to do self-performed abortions. </p></p> <p><p>  YouTube's decision to rely on sources such as the WHO has led to errors regarding COVID-19. It <a href="https://reason.com/2023/04/12/the-media-and-politicians-keep-trying-to-censor-things-that-turn-out-to-be-true/" target="_blank"> censored claims </a> about a laboratory in Wuhan being the origin of the COVID-19 virus, a theory now seen as plausible by several government entities. </p></p> <p><p>  The company also began <a href="https://www.washingtonexaminer.com/policy/technology/youtube--certify-medical-experts-" target="_blank"> certifying health professionals </a> who create medical content in October to ensure users knew which doctors were legitimately trained and which were not.</p></p> <p><p>  <strong> Original Author: </strong> <a href="https://www.washingtonexaminer.com/author/christopher-hutton" target="_blank"> Christopher Hutton </a></p></p> <p><p>  <strong> Original Location: </strong> <a href="https://www.washingtonexaminer.com/policy/technology/youtube-health-misinformation-policy-ban-false-cancer-cures?utm_source=msn&utm_medium=referral&utm_campaign=msn_feed" target="_blank"> YouTube updates health 'misinformation' policy to ban false cancer cures </a></p></p> <div><span>  Continue reading</span></div> <div><h2>  More for You</h2><span>  Feedback</span></div>