{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from deep_translator import GoogleTranslator\n",
    "from langdetect import detect\n",
    "import re\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "import os\n",
    "from bs4 import BeautifulSoup\n",
    "import PyPDF2\n",
    "import json\n",
    "\n",
    "translator = GoogleTranslator(source='auto', target='en')\n",
    "\n",
    "def translate(text):\n",
    "    if len(text) < 5000:\n",
    "        translated = translator.translate(text)\n",
    "    elif len(text) < 9999:\n",
    "        translated = translator.translate(text[:4999]) +\" \"+ translator.translate(text[4999:])\n",
    "    else:\n",
    "        translated = translator.translate(text[:4999]) +\" \"+ translator.translate(text[4999:9998])\n",
    "\n",
    "    return translated\n",
    "\n",
    "\n",
    "def is_english(text):\n",
    "    try:\n",
    "        language = detect(text)\n",
    "        return language == 'en'\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "\n",
    "def split_text_into_chunks(text, max_length):\n",
    "    sentences = re.split(r'(?<=[.!?]) +', text)  # Split text into sentences\n",
    "    chunks = []\n",
    "    current_chunk = \"\"\n",
    "\n",
    "    for sentence in sentences:\n",
    "        if len(current_chunk) + len(sentence) < max_length:\n",
    "            current_chunk += sentence + \" \"\n",
    "        else:\n",
    "            chunks.append(current_chunk.strip())\n",
    "            current_chunk = sentence + \" \"\n",
    "\n",
    "    if current_chunk:\n",
    "        chunks.append(current_chunk.strip())\n",
    "\n",
    "    return chunks\n",
    "\n",
    "def remove_extra_spaces_and_newlines(text):\n",
    "    cleaned_text = re.sub(r'\\s+', ' ', text)\n",
    "    return cleaned_text.strip()\n",
    "\n",
    "\n",
    "\n",
    "DIR_MAPS_PRIVACY_HTML = '../../MAPS Output/HTML Content/'\n",
    "DIR_MAPS_PRIVACY_PDF = '../../MAPS Output/PDF Content/'\n",
    "MAX_LENGTH = 4999\n",
    "\n",
    "def get_privacy_content(domain):\n",
    "    html_folder_path = os.path.join(DIR_MAPS_PRIVACY_HTML, domain)\n",
    "    pdf_folder_path = os.path.join(DIR_MAPS_PRIVACY_PDF, domain)\n",
    "    \n",
    "    html_files_in_folder = os.listdir(DIR_MAPS_PRIVACY_HTML + domain)\n",
    "    pdf_files_in_folder = os.listdir(DIR_MAPS_PRIVACY_PDF + domain)\n",
    "    \n",
    "    content = ''\n",
    "\n",
    "    # Read and process each .txt file\n",
    "    for file in html_files_in_folder:\n",
    "        html_file_path = os.path.join(html_folder_path, file)\n",
    "        with open(html_file_path, 'r', encoding='utf-8') as html_file:\n",
    "            html_content = html_file.read()\n",
    "            soup = BeautifulSoup(html_content, 'html.parser') # Parse the HTML\n",
    "            plain_text = soup.get_text()  # Extract plain text\n",
    "            \n",
    "            text_chunk = split_text_into_chunks(plain_text, MAX_LENGTH)\n",
    "            \n",
    "            for chunk in text_chunk:\n",
    "                if is_english(chunk): content += chunk  # print('NOT ENGLISH') print(chunk)\n",
    "                else: content += translate(chunk) # print('NOT ENGLISH')   # print(chunk)\n",
    "\n",
    "\n",
    "    # Open the PDF file\n",
    "    for file in pdf_files_in_folder:\n",
    "        pdf_file_path = os.path.join(pdf_folder_path, file)        \n",
    "        with open(pdf_file_path, 'r', encoding='utf-8') as pdf_file:\n",
    "            pdf_content = pdf_file.read()\n",
    "\n",
    "            text_chunk = split_text_into_chunks(pdf_content, MAX_LENGTH)\n",
    "\n",
    "            for chunk in text_chunk:\n",
    "                if is_english(chunk): content += chunk  # print('NOT ENGLISH') print(chunk)\n",
    "                else: content += translate(chunk)\n",
    "            \n",
    "    return len(html_files_in_folder), len(pdf_files_in_folder), remove_extra_spaces_and_newlines(content)\n",
    "\n",
    "\n",
    "FILE_SUMMERY = '../../MAPS Output/summery.json'\n",
    "\n",
    "def update_summery(domain, data):\n",
    "    # Read existing JSON data (if any)\n",
    "    existing_data = []\n",
    "    try:\n",
    "        with open(FILE_SUMMERY, 'r') as json_file:\n",
    "            existing_data = json.load(json_file)\n",
    "    except FileNotFoundError:\n",
    "        pass\n",
    "    # Append new data to existing data\n",
    "    existing_data[domain] = data\n",
    "    \n",
    "    # Write the combined data back to the file\n",
    "    with open(FILE_SUMMERY, 'w') as json_file:\n",
    "        json.dump(existing_data, json_file, indent=4)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# file location\n",
    "input_file = '../../Endpoint Mapping Data/Domain Data/v5_unique_domains.csv'\n",
    "output_file = '../../MAPS Output/Cleaned Content/'\n",
    "\n",
    "\n",
    "remote_hostname = pd.read_csv(input_file)\n",
    "# todo testing by sampling \n",
    "remote_hostname=remote_hostname.sample(5)\n",
    "\n",
    "for domain in remote_hostname['domain']:\n",
    "    num_html, num_pdf, privacy_content = get_privacy_content(domain)\n",
    "    # todo uncomment to write in file\n",
    "    # update_summery(domain, {'num_html': num_html, 'num_pdf':num_pdf})\n",
    "    # file_path = os.path.join(output_file, domain+'.txt')\n",
    "    # with open(file_path, 'w', encoding='utf-8') as file:\n",
    "    #     file.write(privacy_content)\n",
    "    print(num_html, num_pdf)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
