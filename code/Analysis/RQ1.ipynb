{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# todo NOTE: this script does not reproduce original result since we removed device IDs \n",
    "# todo NOTE: also this script will encounter runtime/space error since we used device IDs as a key while merge dataframes \n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "file_cleaned_flow = '../../Endpoint Mapping Data/Cleaned Flow/cleaned_flow_stat.csv'\n",
    "cleaned_flow = pd.read_csv(file_cleaned_flow)\n",
    "\n",
    "cleaned_flow['super_vendor'] = cleaned_flow.apply(\n",
    "    lambda row: row.vendor_name.lower() if row.vendor_name==row.vendor_name\n",
    "    else row.gpt_clean_vendor,\n",
    "    axis=1)\n",
    "\n",
    "\n",
    "cleaned_flow['generic_category'] = cleaned_flow.apply(\n",
    "    lambda row: row.man_generic_category if row.man_generic_category==row.man_generic_category\n",
    "    else row.gpt_generic_category,\n",
    "    axis=1)\n",
    "\n",
    "\n",
    "# read all party mapping files\n",
    "file_all_party_mapping = '../../Endpoint Mapping Data/Domain Data/all_party_mapping.csv'\n",
    "all_party_mapping = pd.read_csv(file_all_party_mapping)\n",
    "# drop extra columns \n",
    "all_party_mapping = all_party_mapping[['super_vendor', 'domain', 'party_labels']].drop_duplicates()\n",
    "\n",
    "# marge with clean flow\n",
    "clean_flow_party_label = pd.merge(cleaned_flow,\n",
    "                                  all_party_mapping,\n",
    "                                  on=['super_vendor', 'domain'],\n",
    "                                  how='left'\n",
    "                                  )\n",
    "\n",
    "\n",
    "# read user information file \n",
    "file_user_device_timezone = '../../Inspector Dataset/New data/user_device_timezone.csv'\n",
    "user_device_timezone = pd.read_csv(file_user_device_timezone)\n",
    "user_device_timezone = user_device_timezone[['device_id', 'user_key', 'user_country', 'timezone']]\n",
    "\n",
    "# merge with timezone file \n",
    "clean_flow_party_label = pd.merge(clean_flow_party_label,\n",
    "                                  user_device_timezone,\n",
    "                                  on=['device_id'],\n",
    "                                  how='left'\n",
    "                                  )\n",
    "\n",
    "print(len(clean_flow_party_label['device_id'].unique()))\n",
    "unique_categories = clean_flow_party_label['generic_category'].unique()\n",
    "print(list(unique_categories))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bbe13ec9651290c0"
  },
  {
   "cell_type": "markdown",
   "id": "4c2fecbc",
   "metadata": {},
   "source": [
    "### RQ 1\n",
    "#### How does the distribution of different types of contacted endpoints vary across various categories of IoT devices?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "unique_categories = ['Media/TV',\n",
    "                     'Voice Assistant',\n",
    "                     'Surveillance',\n",
    "                     'Home Automation',\n",
    "                     'Home Appliance ',\n",
    "                     'Game Console',\n",
    "                     'Generic IoT',\n",
    "                     'Work Appliance',\n",
    "                     'Vehicle']\n",
    "\n",
    "devices_df = clean_flow_party_label\n",
    "devices_df['average_out_byte_per_sec'] = devices_df['total_out_byte']/devices_df['flow_duration']\n",
    "threshold = 1e6\n",
    "devices_df=devices_df[devices_df['average_out_byte_per_sec'] < threshold]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "858ddccdfe8a86e2"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#original result\n",
    "# distribution of different types of contacted endpoints vary across various categories of IoT devices\n",
    "aggregated_data = []\n",
    "\n",
    "for category in unique_categories:\n",
    "    df = devices_df[(devices_df['generic_category']==category)]\n",
    "\n",
    "    first_party = len(df[df['party_labels']==1]['domain'].unique())\n",
    "    support_party = len(df[df['party_labels']==2]['domain'].unique())\n",
    "    third_party = len(df[df['party_labels']==3]['domain'].unique())\n",
    "\n",
    "    first = df[df['party_labels']==1].groupby('device_id')['domain'].nunique().reset_index().rename(columns={\"domain\": \"1\"})\n",
    "    support = df[df['party_labels']==2].groupby('device_id')['domain'].nunique().reset_index().rename(columns={\"domain\": \"2\"})\n",
    "    Third = df[df['party_labels']==3].groupby('device_id')['domain'].nunique().reset_index().rename(columns={\"domain\": \"3\"})\n",
    "\n",
    "    devices = df[['device_id']].drop_duplicates()\n",
    "    devices = devices.merge(first,how ='left').merge(support,how ='left').merge(Third,how='left').fillna(0)\n",
    "\n",
    "    first_party_mean, support_party_mean, third_party_mean = devices[['1','2','3']].mean()\n",
    "    first_party_std, support_party_std, third_party_std = devices[['1','2','3']].std()\n",
    "\n",
    "\n",
    "    first_party_up_stream = df[df['party_labels']==1]['average_out_byte_per_sec'].mean()\n",
    "    support_party_up_stream = df[df['party_labels']==2]['average_out_byte_per_sec'].mean()\n",
    "    third_party_up_stream = df[df['party_labels']==3]['average_out_byte_per_sec'].mean()\n",
    "\n",
    "\n",
    "    data = {'Category': category,\n",
    "            'first_party': first_party,\n",
    "            'support_party': support_party,\n",
    "            'third_party': third_party,\n",
    "            'first_party_mean': first_party_mean,\n",
    "            'support_party_mean': support_party_mean,\n",
    "            'third_party_mean': third_party_mean,\n",
    "            'first_party_std': first_party_std,\n",
    "            'support_party_std': support_party_std,\n",
    "            'third_party_std': third_party_std,\n",
    "            'first_party_up_stream': first_party_up_stream,\n",
    "            'support_party_up_stream': support_party_up_stream,\n",
    "            'third_party_up_stream': third_party_up_stream\n",
    "            }\n",
    "\n",
    "    aggregated_data.append(data)\n",
    "    # print(category.ljust(15), ' & ',\n",
    "    #       str(first_party).rjust(6), ' & ','%.2f'.rjust(6) % first_party_mean, ' & ','%.2f'.rjust(6) % first_party_std, ' & ',\n",
    "    #       str(support_party).rjust(6), ' & ', '%.2f'.rjust(6) % support_party_mean, ' & ','%.2f'.rjust(6) % support_party_std, ' & ',\n",
    "    #       str(third_party).rjust(6), ' & ', '%.2f'.rjust(6) % third_party_mean, ' & ', '%.2f'.rjust(6) % third_party_std, '\\\\\\\\[3pt]')\n",
    "\n",
    "rq_1_df = pd.DataFrame(aggregated_data)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fcfd2115de6044e0"
  },
  {
   "cell_type": "markdown",
   "id": "84b3424d",
   "metadata": {},
   "source": [
    "### Block list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "961cb6bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "# Disconnect List\n",
    "\n",
    "file_disconnect = '../../Domain Block Lists/Disconnect-List.json'\n",
    "\n",
    "with open(file_disconnect, encoding=\"utf8\") as f:\n",
    "    disconnect = json.load(f)\n",
    "\n",
    "  \n",
    "disconnect = disconnect['categories']\n",
    "print(disconnect.keys())\n",
    "\n",
    "\n",
    "disconnect_ad_list = []\n",
    "top_list = disconnect['Advertising']\n",
    "\n",
    "for dc_item in top_list:\n",
    "    for dc_item_key in dc_item.keys():\n",
    "        inner_list = dc_item[dc_item_key]\n",
    "        for inner_list_keys in inner_list.keys():\n",
    "            disconnect_ad_list.extend(inner_list[inner_list_keys])     \n",
    "            \n",
    "disconnect_tracklist = []\n",
    "top_list = disconnect['Analytics']\n",
    "\n",
    "for dc_item in top_list:\n",
    "    for dc_item_key in dc_item.keys():\n",
    "        inner_list = dc_item[dc_item_key]\n",
    "        for inner_list_keys in inner_list.keys():\n",
    "            disconnect_tracklist.extend(inner_list[inner_list_keys])  \n",
    "            \n",
    "disconnect_list = []\n",
    "\n",
    "for key in disconnect.keys():\n",
    "    top_list = disconnect[key]\n",
    "    for dc_item in top_list:\n",
    "        for dc_item_key in dc_item.keys():\n",
    "            inner_list = dc_item[dc_item_key]\n",
    "            for inner_list_keys in inner_list.keys():\n",
    "                disconnect_list.extend(inner_list[inner_list_keys])    \n",
    "\n",
    "print(len(disconnect_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Create Database for WhoTracksMe\n",
    "import sqlite3\n",
    "\n",
    "#Connect to Database\n",
    "con = sqlite3.connect('WhoTracksMe.db')\n",
    "cur = con.cursor()\n",
    "whotracksme_file = '../../Domain Block Lists/trackerdb.sql'\n",
    "#read file\n",
    "f= open(whotracksme_file,mode='r',encoding='utf8', newline='\\n')\n",
    "whotracksme_lines = [line.replace('\\n', '') for line in f]\n",
    "whotracksme_query = []\n",
    "query = ''\n",
    "for line in whotracksme_lines:\n",
    "    query += line\n",
    "    if query[-1] == ';':\n",
    "        whotracksme_query.append(query)\n",
    "        query = ''\n",
    "for query in whotracksme_query:\n",
    "    cur.execute(query)\n",
    "con.commit()\n",
    "\n",
    "# read a table       \n",
    "sql_query = pd.read_sql('SELECT * FROM tracker_domains', con)\n",
    "whotracksme_tracklist = sql_query['domain'].unique()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "755f1b59b634b9c3"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0ba082d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Easy Privacy \n",
    "file_easy_list = '../../Domain Block Lists/easylist.txt'\n",
    "file_easy_privacy = '../../Domain Block Lists/easyprivacy.txt'\n",
    "\n",
    "\n",
    "with open(file_easy_list, encoding=\"utf8\") as f:\n",
    "    easy_list = [line[2:].split(\"^\")[0] for line in f if line.startswith('||')]\n",
    "    \n",
    "with open(file_easy_privacy, encoding=\"utf8\") as f:\n",
    "    easy_privacy = [line[2:].split(\"^\")[0] for line in f if line.startswith('||')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af8be36d",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_duckduckgo = '../../Domain Block Lists/duckduckgo_categorized_trackers.csv'\n",
    "duckduckgo_domains = pd.read_csv(file_duckduckgo)\n",
    "\n",
    "duckduckgo_advertising = duckduckgo_domains[duckduckgo_domains['Advertising'] == 1]['domain'].unique()\n",
    "duckduckgo_tracking = duckduckgo_domains[duckduckgo_domains['Ad Motivated Tracking'] == 1]['domain'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66143764",
   "metadata": {},
   "outputs": [],
   "source": [
    "category =   'Home Automation'\n",
    "\n",
    "third_parties = devices_df[(devices_df['generic_category']==category) & (devices_df['party_labels']==3)]['domain'].unique()\n",
    "\n",
    "ad_domain = []\n",
    "track_domain = []\n",
    "for party in third_parties:\n",
    "    if (party in disconnect_list) \\\n",
    "    or (party in easy_list) \\\n",
    "    or (party in duckduckgo_advertising) : ad_domain.append(party)\n",
    "        \n",
    "    if (party in whotracksme_tracklist) \\\n",
    "    or (party in easy_privacy) \\\n",
    "    or (party in duckduckgo_tracking): track_domain.append(party)\n",
    "\n",
    "print(len(ad_domain))\n",
    "print(len(track_domain))\n",
    "print(len(third_parties))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "### Find ad services in simple devices \n",
    "gpt_device_category_merged = pd.read_csv('../../Device Identification/Device Category Mapping/gpt_device_id_generic_category.csv')[['device_id', 'gpt_clean_vendor', 'gpt_clean_type','generic_category']].rename(columns={'generic_category':'gpt_generic_category'})\n",
    "\n",
    "simple_devices = gpt_device_category_merged[(gpt_device_category_merged.gpt_clean_type.str.contains('Plug')) |\n",
    "                                            (gpt_device_category_merged.gpt_clean_type.str.contains('Bulb')) |\n",
    "                                            (gpt_device_category_merged.gpt_clean_type.str.contains('Switch')) |\n",
    "                                            (gpt_device_category_merged.gpt_clean_type.str.contains('Light'))  ][['device_id']]\n",
    "simple_devices = pd.merge(simple_devices, devices_df, on='device_id', how='inner')\n",
    "simple_devices = simple_devices[simple_devices.generic_category=='Home Automation']\n",
    "third_parties = simple_devices['domain'].unique()\n",
    "\n",
    "ad_domain = []\n",
    "track_domain = []\n",
    "for party in third_parties:\n",
    "    if (party in disconnect_list) \\\n",
    "            or (party in easy_list) \\\n",
    "            or (party in duckduckgo_advertising) : ad_domain.append(party)\n",
    "\n",
    "    if (party in whotracksme_tracklist) \\\n",
    "            or (party in easy_privacy) \\\n",
    "            or (party in duckduckgo_tracking): track_domain.append(party)\n",
    "\n",
    "print(len(ad_domain))\n",
    "print(len(track_domain))\n",
    "print(len(third_parties))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1b68ffb0fbc63647"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ddict = {}\n",
    "ad_domain.extend(track_domain)\n",
    "for item in ad_domain:\n",
    "    ddict[item]=1\n",
    "\n",
    "print(len(ddict))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cf472fcf246b2ca3"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "## find advertiser percentage\n",
    "third_parties = devices_df[(devices_df['party_labels']==3)]['domain'].unique()\n",
    "\n",
    "ad_domain = []\n",
    "track_domain = []\n",
    "for party in third_parties:\n",
    "    if (party in disconnect_list) \\\n",
    "            or (party in easy_list) \\\n",
    "            or (party in duckduckgo_advertising) : ad_domain.append(party)\n",
    "\n",
    "    if (party in whotracksme_tracklist) \\\n",
    "            or (party in easy_privacy) \\\n",
    "            or (party in duckduckgo_tracking): track_domain.append(party)\n",
    "\n",
    "print(len(ad_domain))\n",
    "print(len(track_domain))\n",
    "print(len(third_parties))\n",
    "\n",
    "ddict = {}\n",
    "ad_domain.extend(track_domain)\n",
    "for item in ad_domain:\n",
    "    ddict[item]=1\n",
    "\n",
    "print(len(ddict))\n",
    "print('percentage: ', 100*len(ddict)/len(third_parties))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ec6707442ec847e"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
