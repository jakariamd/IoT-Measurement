{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# todo NOTE: this script does not reproduce original result since we removed device IDs \n",
    "# todo NOTE: also this script will encounter runtime/space error since we used device IDs as a key while merge dataframes \n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "file_cleaned_flow = '../../../Endpoint Mapping Data/Cleaned Flow/cleaned_flow_stat.csv'\n",
    "cleaned_flow = pd.read_csv(file_cleaned_flow)\n",
    "\n",
    "cleaned_flow['super_vendor'] = cleaned_flow.apply(\n",
    "    lambda row: row.vendor_name.lower() if row.vendor_name==row.vendor_name\n",
    "    else row.gpt_clean_vendor,\n",
    "    axis=1)\n",
    "\n",
    "\n",
    "cleaned_flow['generic_category'] = cleaned_flow.apply(\n",
    "    lambda row: row.man_generic_category if row.man_generic_category==row.man_generic_category\n",
    "    else row.gpt_generic_category,\n",
    "    axis=1)\n",
    "\n",
    "\n",
    "# read all party mapping files\n",
    "file_all_party_mapping = '../../../Endpoint Mapping Data/Domain Data/all_party_mapping.csv'\n",
    "all_party_mapping = pd.read_csv(file_all_party_mapping)\n",
    "# drop extra columns \n",
    "all_party_mapping = all_party_mapping[['super_vendor', 'domain', 'party_labels']].drop_duplicates()\n",
    "\n",
    "# marge with clean flow\n",
    "clean_flow_party_label = pd.merge(cleaned_flow,\n",
    "                                  all_party_mapping,\n",
    "                                  on=['super_vendor', 'domain'],\n",
    "                                  how='left'\n",
    "                                  )\n",
    "\n",
    "\n",
    "# read user information file \n",
    "file_user_device_timezone = '../../../Inspector Dataset/New data/user_device_timezone.csv'\n",
    "user_device_timezone = pd.read_csv(file_user_device_timezone)\n",
    "user_device_timezone = user_device_timezone[['device_id', 'user_key', 'user_country', 'timezone']]\n",
    "\n",
    "# merge with timezone file \n",
    "clean_flow_party_label = pd.merge(clean_flow_party_label,\n",
    "                                  user_device_timezone,\n",
    "                                  on=['device_id'],\n",
    "                                  how='left'\n",
    "                                  )\n",
    "\n",
    "unique_categories = ['Media/TV',\n",
    "                     'Home Automation',\n",
    "                     'Voice Assistant',\n",
    "                     'Surveillance',\n",
    "                     'Game Console',\n",
    "                     'Work Appliance',\n",
    "                     'Home Appliance ',\n",
    "                     'Generic IoT',]\n",
    "# 'Vehicle']\n",
    "\n",
    "\n",
    "clean_flow_party_label['average_out_byte_per_sec'] = clean_flow_party_label['total_out_byte']/clean_flow_party_label['flow_duration']\n",
    "threshold = 1e6\n",
    "# Replace values greater than the threshold with NaN\n",
    "clean_flow_party_label['average_out_byte_per_sec'] = np.where(clean_flow_party_label['average_out_byte_per_sec'] > threshold, \n",
    "                                                              np.nan, clean_flow_party_label['average_out_byte_per_sec'])"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f914e8037b575471"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#original result\n",
    "# distribution of different types of contacted endpoints vary across various categories of IoT devices\n",
    "\n",
    "def analyze_rq_1(device_df):\n",
    "    aggregated_data = []\n",
    "    \n",
    "    for category in unique_categories:\n",
    "        df = device_df[(device_df['generic_category']==category)]\n",
    "    \n",
    "        # Get number of domains of each type within this category\n",
    "        first_party = len(df[df['party_labels']==1]['domain'].unique())\n",
    "        support_party = len(df[df['party_labels']==2]['domain'].unique())\n",
    "        third_party = len(df[df['party_labels']==3]['domain'].unique())\n",
    "    \n",
    "        first = df[df['party_labels']==1].groupby('device_id')['domain'].nunique().reset_index().rename(columns={\"domain\": \"1\"})\n",
    "        support = df[df['party_labels']==2].groupby('device_id')['domain'].nunique().reset_index().rename(columns={\"domain\": \"2\"})\n",
    "        Third = df[df['party_labels']==3].groupby('device_id')['domain'].nunique().reset_index().rename(columns={\"domain\": \"3\"})\n",
    "    \n",
    "        devices = df[['device_id']].drop_duplicates()\n",
    "        devices = devices.merge(first,how ='left').merge(support,how ='left').merge(Third,how='left').fillna(0)\n",
    "    \n",
    "        first_party_mean, support_party_mean, third_party_mean = devices[['1','2','3']].mean()\n",
    "        first_party_std, support_party_std, third_party_std = devices[['1','2','3']].std()\n",
    "    \n",
    "    \n",
    "        first_party_up_stream = df[df['party_labels']==1]['average_out_byte_per_sec'].mean()\n",
    "        support_party_up_stream = df[df['party_labels']==2]['average_out_byte_per_sec'].mean()\n",
    "        third_party_up_stream = df[df['party_labels']==3]['average_out_byte_per_sec'].mean()\n",
    "    \n",
    "        first_party_up_stream_std = df[df['party_labels']==1]['average_out_byte_per_sec'].std()\n",
    "        support_party_up_stream_std = df[df['party_labels']==2]['average_out_byte_per_sec'].std()\n",
    "        third_party_up_stream_std = df[df['party_labels']==3]['average_out_byte_per_sec'].std()\n",
    "    \n",
    "    \n",
    "        data = {'Category': category,\n",
    "                'first_party': first_party,\n",
    "                'support_party': support_party,\n",
    "                'third_party': third_party,\n",
    "                'first_party_mean': first_party_mean,\n",
    "                'support_party_mean': support_party_mean,\n",
    "                'third_party_mean': third_party_mean,\n",
    "                'first_party_std': first_party_std,\n",
    "                'support_party_std': support_party_std,\n",
    "                'third_party_std': third_party_std,\n",
    "                'first_party_up_stream': first_party_up_stream,\n",
    "                'support_party_up_stream': support_party_up_stream,\n",
    "                'third_party_up_stream': third_party_up_stream,\n",
    "                'first_party_up_stream_std': first_party_up_stream_std,\n",
    "                'support_party_up_stream_std': support_party_up_stream_std,\n",
    "                'third_party_up_stream_std': third_party_up_stream_std\n",
    "                }\n",
    "    \n",
    "        aggregated_data.append(data)\n",
    "    return pd.DataFrame(aggregated_data)\n",
    "\n",
    "rq_1_df = analyze_rq_1(clean_flow_party_label.copy())"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5a1000ef3ea5ee56"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def sample_devices(devices_data, seed, sample_size, device_categories):\n",
    "    np.random.seed(seed)\n",
    "    sampled_data = devices_data[devices_data['generic_category'].isin(device_categories)][['device_id',\n",
    "                                                                                           'generic_category']].drop_duplicates()\n",
    "    sampled_data = sampled_data.groupby('generic_category').apply(\n",
    "        lambda x: x.sample(n=sample_size)).reset_index(drop=True)\n",
    "\n",
    "    sampled_data = sampled_data[['device_id']]\n",
    "    return pd.merge(sampled_data, clean_flow_party_label,\n",
    "                    on=['device_id'],\n",
    "                    how='inner'\n",
    "                    )\n",
    "\n",
    "# sampled result\n",
    "# distribution of different types of contacted endpoints vary across various categories of IoT devices\n",
    "# On sampled data\n",
    "\n",
    "def sample_analysis(device_flow_data, device_categories):\n",
    "    devices_df = device_flow_data.copy()\n",
    "\n",
    "    aggregated_data = []\n",
    "\n",
    "    for category in device_categories:\n",
    "        df = devices_df[(devices_df['generic_category']==category)]\n",
    "\n",
    "        # Get number of domains of each type within this category\n",
    "        first_party = len(df[df['party_labels']==1]['domain'].unique())\n",
    "        support_party = len(df[df['party_labels']==2]['domain'].unique())\n",
    "        third_party = len(df[df['party_labels']==3]['domain'].unique())\n",
    "\n",
    "        first = df[df['party_labels']==1].groupby('device_id')['domain'].nunique().reset_index().rename(columns={\"domain\": \"1\"})\n",
    "        support = df[df['party_labels']==2].groupby('device_id')['domain'].nunique().reset_index().rename(columns={\"domain\": \"2\"})\n",
    "        Third = df[df['party_labels']==3].groupby('device_id')['domain'].nunique().reset_index().rename(columns={\"domain\": \"3\"})\n",
    "\n",
    "        devices = df[['device_id']].drop_duplicates()\n",
    "        devices = devices.merge(first,how ='left').merge(support,how ='left').merge(Third,how='left').fillna(0)\n",
    "\n",
    "        first_party_mean, support_party_mean, third_party_mean = devices[['1','2','3']].mean()\n",
    "        first_party_std, support_party_std, third_party_std = devices[['1','2','3']].std()\n",
    "\n",
    "\n",
    "        first_party_up_stream = df[df['party_labels']==1]['average_out_byte_per_sec'].mean()\n",
    "        support_party_up_stream = df[df['party_labels']==2]['average_out_byte_per_sec'].mean()\n",
    "        third_party_up_stream = df[df['party_labels']==3]['average_out_byte_per_sec'].mean()\n",
    "\n",
    "        first_party_up_stream_std = df[df['party_labels']==1]['average_out_byte_per_sec'].std()\n",
    "        support_party_up_stream_std = df[df['party_labels']==2]['average_out_byte_per_sec'].std()\n",
    "        third_party_up_stream_std = df[df['party_labels']==3]['average_out_byte_per_sec'].std()\n",
    "\n",
    "\n",
    "        data = {'Category': category,\n",
    "                'first_party': first_party,\n",
    "                'support_party': support_party,\n",
    "                'third_party': third_party,\n",
    "                'first_party_mean': first_party_mean,\n",
    "                'support_party_mean': support_party_mean,\n",
    "                'third_party_mean': third_party_mean,\n",
    "                'first_party_std': first_party_std,\n",
    "                'support_party_std': support_party_std,\n",
    "                'third_party_std': third_party_std,\n",
    "                'first_party_up_stream': first_party_up_stream,\n",
    "                'support_party_up_stream': support_party_up_stream,\n",
    "                'third_party_up_stream': third_party_up_stream,\n",
    "                'first_party_up_stream_std': first_party_up_stream_std,\n",
    "                'support_party_up_stream_std': support_party_up_stream_std,\n",
    "                'third_party_up_stream_std': third_party_up_stream_std\n",
    "                }\n",
    "\n",
    "        aggregated_data.append(data)\n",
    "    return pd.DataFrame(aggregated_data)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "929c3a0843d443e3"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sampled_devices_df_40 = sample_devices(devices_data=clean_flow_party_label.copy(),\n",
    "                                       seed=40,\n",
    "                                       sample_size=3000,\n",
    "                                       device_categories=['Media/TV', 'Home Automation', 'Voice Assistant'])\n",
    "\n",
    "sampled_devices_df_42 = sample_devices(devices_data=clean_flow_party_label.copy(),\n",
    "                                       seed=42,\n",
    "                                       sample_size=3000,\n",
    "                                       device_categories=['Media/TV', 'Home Automation', 'Voice Assistant'])\n",
    "\n",
    "sampled_devices_df_44 = sample_devices(devices_data=clean_flow_party_label.copy(),\n",
    "                                       seed=44,\n",
    "                                       sample_size=3000,\n",
    "                                       device_categories=['Media/TV', 'Home Automation', 'Voice Assistant'])\n",
    "\n",
    "rq_1_df_sampled_40 = sample_analysis(device_flow_data=sampled_devices_df_40,\n",
    "                                     device_categories=['Media/TV', 'Home Automation', 'Voice Assistant'])\n",
    "\n",
    "rq_1_df_sampled_42 = sample_analysis(device_flow_data=sampled_devices_df_42,\n",
    "                                     device_categories=['Media/TV', 'Home Automation', 'Voice Assistant'])\n",
    "\n",
    "rq_1_df_sampled_44 = sample_analysis(device_flow_data=sampled_devices_df_44,\n",
    "                                     device_categories=['Media/TV', 'Home Automation', 'Voice Assistant'])\n",
    "\n",
    "\n",
    "# Find the mean values for all samples\n",
    "rq_1_df_sampled_mean = [rq_1_df_sampled_40, rq_1_df_sampled_42, rq_1_df_sampled_44]\n",
    "rq_1_df_sampled_mean = pd.concat(rq_1_df_sampled_mean).groupby('Category').mean().reindex(['Media/TV', 'Home Automation', 'Voice Assistant']).reset_index()\n",
    "\n",
    "sampled_device_categories = ['Media/TV', 'Home Automation', 'Voice Assistant']\n",
    "rq_1_df_all =  rq_1_df[rq_1_df['Category'].isin(sampled_device_categories)]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "87235000a671c9aa"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "matplotlib.use('QtAgg')  # Choose the appropriate backend\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('default')  # Set the default style\n",
    "\n",
    "# Assuming your DataFrame is named df\n",
    "# Replace 'category', 'total', 'avg', 'std' with the actual column names\n",
    "\n",
    "# Create a figure with subplots\n",
    "fig, axes = plt.subplots(nrows=2, ncols=3, figsize=(9, 4), sharex=True)\n",
    "colors = ['blue', 'green', 'red']\n",
    "\n",
    "# Bar width\n",
    "bar_width = 0.3\n",
    "capsize = 2\n",
    "log_scale = True\n",
    "alpha = 0.5\n",
    "# Position of bars on X-axis\n",
    "bar_positions_1 = np.arange(-0.3, 2 , 1).tolist()\n",
    "# bar_positions_1 = range(0,9)\n",
    "bar_positions_2 = [pos + bar_width for pos in bar_positions_1]\n",
    "bar_positions_3 = [pos + bar_width for pos in bar_positions_2]\n",
    "\n",
    "# Plot bar plots for each column with respect to 'category'\n",
    "# Melt the DataFrame to 'long' format for easy plotting\n",
    "\n",
    "df = rq_1_df_sampled_mean.copy()\n",
    "df['short_category'] = df['Category'].astype(str).str[0:8]\n",
    "df_melted = pd.melt(df[['short_category', 'first_party', 'support_party', 'third_party']],\n",
    "                    id_vars='short_category', var_name='party_type', value_name='total_domain')\n",
    "\n",
    "sns.barplot(x='short_category', y='total_domain', data=df_melted, hue='party_type', ax=axes[0][0],\n",
    "            width=0.8, log=True, palette=colors, alpha=0.6, edgecolor='black', linewidth=0.5)\n",
    "\n",
    "axes[0][0].set_title('1. Total # of domains')\n",
    "# axes[0][0].legend(loc='center left', bbox_to_anchor=(0.6, 0.855), prop={'size': 6}, )\n",
    "# Hide x-axis and y-axis labels\n",
    "axes[0][0].legend().set_visible(False)\n",
    "axes[0][0].set_xlabel('')  # Hide x-axis label on axes[0]\n",
    "axes[0][0].set_ylabel('Sampled devices')  # Hide x-axis label on axes[0]\n",
    "\n",
    "# Plot mean values\n",
    "axes[0][1].bar(bar_positions_1, df['first_party_mean'],\n",
    "               width=bar_width, label='Mean 1', yerr=df['first_party_std'],\n",
    "               capsize=capsize, log=log_scale,  color=colors[0], alpha=alpha, edgecolor='black', linewidth=0.5)\n",
    "\n",
    "axes[0][1].bar(bar_positions_2, df['support_party_mean'],\n",
    "               width=bar_width, label='Mean 1', yerr=df['support_party_std'],\n",
    "               capsize=capsize, log=log_scale, color=colors[1], alpha=alpha, edgecolor='black', linewidth=0.5)\n",
    "\n",
    "axes[0][1].bar(bar_positions_3, df['third_party_mean'],\n",
    "               width=bar_width, label='Mean 1', yerr=df['third_party_std'],\n",
    "               capsize=capsize, log=log_scale, color=colors[2], alpha=alpha, edgecolor='black', linewidth=0.5)\n",
    "axes[0][1].set_title('2. Average # of Domain')\n",
    "\n",
    "\n",
    "# plot upstream data\n",
    "\n",
    "axes[0][2].bar(bar_positions_1, df['first_party_up_stream'],\n",
    "               width=bar_width, label='Mean 1',\n",
    "               capsize=capsize, log=log_scale,  color=colors[0], alpha=alpha, edgecolor='black', linewidth=0.5)\n",
    "\n",
    "axes[0][2].bar(bar_positions_2, df['support_party_up_stream'],\n",
    "               width=bar_width, label='Mean 1',\n",
    "               capsize=capsize, log=log_scale, color=colors[1], alpha=alpha, edgecolor='black', linewidth=0.5)\n",
    "\n",
    "axes[0][2].bar(bar_positions_3, df['third_party_up_stream'],\n",
    "               width=bar_width, label='Mean 1',\n",
    "               capsize=capsize, log=log_scale, color=colors[2], alpha=alpha, edgecolor='black', linewidth=0.5)\n",
    "\n",
    "axes[0][2].set_title('3. Volume of up-stream data')\n",
    "\n",
    "legend_names = ['First-party', 'Support-party', 'Third-party']\n",
    "\n",
    "axes[0][2].legend(legend_names, loc='center left', bbox_to_anchor=(.58, .81), prop={'size': 6}, )\n",
    "\n",
    "\n",
    "# Plot bar plots for each column with respect to 'category'\n",
    "# Melt the DataFrame to 'long' format for easy plotting\n",
    "\n",
    "df = rq_1_df_all.copy()\n",
    "df['short_category'] = df['Category'].astype(str).str[0:8]\n",
    "df_melted = pd.melt(df[['short_category', 'first_party', 'support_party', 'third_party']],\n",
    "                    id_vars='short_category', var_name='party_type', value_name='total_domain')\n",
    "\n",
    "sns.barplot(x='short_category', y='total_domain', data=df_melted, hue='party_type', ax=axes[1][0],\n",
    "            width=0.8, log=True, palette=colors, alpha=0.6, edgecolor='black', linewidth=0.5)\n",
    "\n",
    "# axes[1][0].set_title('1. Total # of domains')\n",
    "# axes[1][0].legend(loc='center left', bbox_to_anchor=(0.6, 0.855), prop={'size': 6}, )\n",
    "axes[1][0].legend().set_visible(False)\n",
    "# Hide x-axis and y-axis labels\n",
    "axes[1][0].set_xlabel('')  # Hide x-axis label on axes[0]\n",
    "axes[1][0].set_ylabel('All devices')  # Hide x-axis label on axes[0]\n",
    "\n",
    "\n",
    "# Plot mean values\n",
    "axes[1][1].bar(bar_positions_1, df['first_party_mean'],\n",
    "               width=bar_width, label='Mean 1', yerr=df['first_party_std'],\n",
    "               capsize=capsize, log=log_scale,  color=colors[0], alpha=alpha, edgecolor='black', linewidth=0.5)\n",
    "\n",
    "axes[1][1].bar(bar_positions_2, df['support_party_mean'],\n",
    "               width=bar_width, label='Mean 1', yerr=df['support_party_std'],\n",
    "               capsize=capsize, log=log_scale, color=colors[1], alpha=alpha, edgecolor='black', linewidth=0.5)\n",
    "\n",
    "axes[1][1].bar(bar_positions_3, df['third_party_mean'],\n",
    "               width=bar_width, label='Mean 1', yerr=df['third_party_std'],\n",
    "               capsize=capsize, log=log_scale, color=colors[2], alpha=alpha, edgecolor='black', linewidth=0.5)\n",
    "# axes[1][1].set_title('2. Average # of Domain')\n",
    "\n",
    "\n",
    "# plot upstream data\n",
    "\n",
    "axes[1][2].bar(bar_positions_1, df['first_party_up_stream'],\n",
    "               width=bar_width, label='Mean 1',\n",
    "               capsize=capsize, log=log_scale,  color=colors[0], alpha=alpha, edgecolor='black', linewidth=0.5)\n",
    "\n",
    "axes[1][2].bar(bar_positions_2, df['support_party_up_stream'],\n",
    "               width=bar_width, label='Mean 1',\n",
    "               capsize=capsize, log=log_scale, color=colors[1], alpha=alpha, edgecolor='black', linewidth=0.5)\n",
    "\n",
    "axes[1][2].bar(bar_positions_3, df['third_party_up_stream'],\n",
    "               width=bar_width, label='Mean 1',\n",
    "               capsize=capsize, log=log_scale, color=colors[2], alpha=alpha, edgecolor='black', linewidth=0.5)\n",
    "\n",
    "# axes[1][2].set_title('3. Volume of up-stream data')\n",
    "\n",
    "# Rotate category names vertically\n",
    "for ax in axes[1]:\n",
    "    ax.set_xticklabels(ax.get_xticklabels(), rotation=30, ha='center')\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "# todo save and show the plot\n",
    "# plt.savefig('../../Statistical Data/Appendix/sample-plot.pdf')\n",
    "plt.show()\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "69d8f5f812ceb4b1"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Sample all device categories\n",
    "\n",
    "sampled_devices_all_40 = sample_devices(devices_data=clean_flow_party_label.copy(),\n",
    "                                       seed=40,\n",
    "                                       sample_size=50,\n",
    "                                       device_categories=unique_categories)\n",
    "\n",
    "sampled_devices_all_42 = sample_devices(devices_data=clean_flow_party_label.copy(),\n",
    "                                        seed=42,\n",
    "                                        sample_size=50,\n",
    "                                        device_categories=unique_categories)\n",
    "\n",
    "sampled_devices_all_44 = sample_devices(devices_data=clean_flow_party_label.copy(),\n",
    "                                        seed=44,\n",
    "                                        sample_size=50,\n",
    "                                        device_categories=unique_categories)\n",
    "\n",
    "\n",
    "rq_1_df_sampled_all_40 = sample_analysis(device_flow_data=sampled_devices_all_40,\n",
    "                                         device_categories=unique_categories)\n",
    "\n",
    "rq_1_df_sampled_all_42 = sample_analysis(device_flow_data=sampled_devices_all_42,\n",
    "                                         device_categories=unique_categories)\n",
    "\n",
    "rq_1_df_sampled_all_44 = sample_analysis(device_flow_data=sampled_devices_all_44,\n",
    "                                         device_categories=unique_categories)\n",
    "\n",
    "# Find the mean values for all samples\n",
    "rq_1_df_sampled_all_mean = [rq_1_df_sampled_all_40, rq_1_df_sampled_all_42, rq_1_df_sampled_all_44]\n",
    "rq_1_df_sampled_all_mean = pd.concat(rq_1_df_sampled_all_mean).groupby('Category').mean().reindex(unique_categories).reset_index()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6fdc770de666b7e9"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "matplotlib.use('QtAgg')  # Choose the appropriate backend\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming your DataFrame is named df\n",
    "# Replace 'category', 'total', 'avg', 'std' with the actual column names\n",
    "\n",
    "# Create a figure with subplots\n",
    "fig, axes = plt.subplots(nrows=2, ncols=3, figsize=(9, 4), sharex=True)\n",
    "colors = ['blue', 'green', 'red']\n",
    "\n",
    "# Bar width\n",
    "bar_width = 0.3\n",
    "capsize = 2\n",
    "log_scale = True\n",
    "alpha = 0.5\n",
    "# Position of bars on X-axis\n",
    "bar_positions_1 = np.arange(-0.3, 7 , 1).tolist()\n",
    "# bar_positions_1 = range(0,9)\n",
    "bar_positions_2 = [pos + bar_width for pos in bar_positions_1]\n",
    "bar_positions_3 = [pos + bar_width for pos in bar_positions_2]\n",
    "\n",
    "# Plot bar plots for each column with respect to 'category'\n",
    "# Melt the DataFrame to 'long' format for easy plotting\n",
    "\n",
    "df = rq_1_df_sampled_all_mean.copy()\n",
    "df['short_category'] = df['Category'].astype(str).str[0:8]\n",
    "df_melted = pd.melt(df[['short_category', 'first_party', 'support_party', 'third_party']],\n",
    "                    id_vars='short_category', var_name='party_type', value_name='total_domain')\n",
    "\n",
    "sns.barplot(x='short_category', y='total_domain', data=df_melted, hue='party_type', ax=axes[0][0],\n",
    "            width=0.8, log=True, palette=colors, alpha=0.6, edgecolor='black', linewidth=0.5)\n",
    "\n",
    "axes[0][0].set_title('1. Total # of domains')\n",
    "# axes[0][0].legend(loc='center left', bbox_to_anchor=(0.6, 0.855), prop={'size': 6}, )\n",
    "# Hide x-axis and y-axis labels\n",
    "axes[0][0].legend().set_visible(False)\n",
    "axes[0][0].set_xlabel('')  # Hide x-axis label on axes[0]\n",
    "axes[0][0].set_ylabel('Sampled devices')  # Hide x-axis label on axes[0]\n",
    "\n",
    "# Plot mean values\n",
    "axes[0][1].bar(bar_positions_1, df['first_party_mean'],\n",
    "               width=bar_width, label='Mean 1', yerr=df['first_party_std'],\n",
    "               capsize=capsize, log=log_scale,  color=colors[0], alpha=alpha, edgecolor='black', linewidth=0.5)\n",
    "\n",
    "axes[0][1].bar(bar_positions_2, df['support_party_mean'],\n",
    "               width=bar_width, label='Mean 1', yerr=df['support_party_std'],\n",
    "               capsize=capsize, log=log_scale, color=colors[1], alpha=alpha, edgecolor='black', linewidth=0.5)\n",
    "\n",
    "axes[0][1].bar(bar_positions_3, df['third_party_mean'],\n",
    "               width=bar_width, label='Mean 1', yerr=df['third_party_std'],\n",
    "               capsize=capsize, log=log_scale, color=colors[2], alpha=alpha, edgecolor='black', linewidth=0.5)\n",
    "axes[0][1].set_title('2. Average # of Domain')\n",
    "\n",
    "\n",
    "# plot upstream data\n",
    "\n",
    "axes[0][2].bar(bar_positions_1, df['first_party_up_stream'],\n",
    "               width=bar_width, label='Mean 1',\n",
    "               capsize=capsize, log=log_scale,  color=colors[0], alpha=alpha, edgecolor='black', linewidth=0.5)\n",
    "\n",
    "axes[0][2].bar(bar_positions_2, df['support_party_up_stream'],\n",
    "               width=bar_width, label='Mean 1',\n",
    "               capsize=capsize, log=log_scale, color=colors[1], alpha=alpha, edgecolor='black', linewidth=0.5)\n",
    "\n",
    "axes[0][2].bar(bar_positions_3, df['third_party_up_stream'],\n",
    "               width=bar_width, label='Mean 1',\n",
    "               capsize=capsize, log=log_scale, color=colors[2], alpha=alpha, edgecolor='black', linewidth=0.5)\n",
    "\n",
    "axes[0][2].set_title('3. Volume of up-stream data')\n",
    "\n",
    "legend_names = ['First-party', 'Support-party', 'Third-party']\n",
    "\n",
    "axes[0][2].legend(legend_names, loc='center left', bbox_to_anchor=(.58, .81), prop={'size': 6}, )\n",
    "\n",
    "\n",
    "# Plot bar plots for each column with respect to 'category'\n",
    "# Melt the DataFrame to 'long' format for easy plotting\n",
    "\n",
    "df = rq_1_df.copy()\n",
    "df['short_category'] = df['Category'].astype(str).str[0:8]\n",
    "df_melted = pd.melt(df[['short_category', 'first_party', 'support_party', 'third_party']],\n",
    "                    id_vars='short_category', var_name='party_type', value_name='total_domain')\n",
    "\n",
    "sns.barplot(x='short_category', y='total_domain', data=df_melted, hue='party_type', ax=axes[1][0],\n",
    "            width=0.8, log=True, palette=colors, alpha=0.6, edgecolor='black', linewidth=0.5)\n",
    "\n",
    "# axes[1][0].set_title('1. Total # of domains')\n",
    "# axes[1][0].legend(loc='center left', bbox_to_anchor=(0.6, 0.855), prop={'size': 6}, )\n",
    "axes[1][0].legend().set_visible(False)\n",
    "# Hide x-axis and y-axis labels\n",
    "axes[1][0].set_xlabel('')  # Hide x-axis label on axes[0]\n",
    "axes[1][0].set_ylabel('All devices')  # Hide x-axis label on axes[0]\n",
    "\n",
    "\n",
    "# Plot mean values\n",
    "axes[1][1].bar(bar_positions_1, df['first_party_mean'],\n",
    "               width=bar_width, label='Mean 1', yerr=df['first_party_std'],\n",
    "               capsize=capsize, log=log_scale,  color=colors[0], alpha=alpha, edgecolor='black', linewidth=0.5)\n",
    "\n",
    "axes[1][1].bar(bar_positions_2, df['support_party_mean'],\n",
    "               width=bar_width, label='Mean 1', yerr=df['support_party_std'],\n",
    "               capsize=capsize, log=log_scale, color=colors[1], alpha=alpha, edgecolor='black', linewidth=0.5)\n",
    "\n",
    "axes[1][1].bar(bar_positions_3, df['third_party_mean'],\n",
    "               width=bar_width, label='Mean 1', yerr=df['third_party_std'],\n",
    "               capsize=capsize, log=log_scale, color=colors[2], alpha=alpha, edgecolor='black', linewidth=0.5)\n",
    "# axes[1][1].set_title('2. Average # of Domain')\n",
    "\n",
    "\n",
    "# plot upstream data\n",
    "\n",
    "axes[1][2].bar(bar_positions_1, df['first_party_up_stream'],\n",
    "               width=bar_width, label='Mean 1',\n",
    "               capsize=capsize, log=log_scale,  color=colors[0], alpha=alpha, edgecolor='black', linewidth=0.5)\n",
    "\n",
    "axes[1][2].bar(bar_positions_2, df['support_party_up_stream'],\n",
    "               width=bar_width, label='Mean 1',\n",
    "               capsize=capsize, log=log_scale, color=colors[1], alpha=alpha, edgecolor='black', linewidth=0.5)\n",
    "\n",
    "axes[1][2].bar(bar_positions_3, df['third_party_up_stream'],\n",
    "               width=bar_width, label='Mean 1',\n",
    "               capsize=capsize, log=log_scale, color=colors[2], alpha=alpha, edgecolor='black', linewidth=0.5)\n",
    "\n",
    "# axes[1][2].set_title('3. Volume of up-stream data')\n",
    "\n",
    "# Rotate category names vertically\n",
    "for ax in axes[1]:\n",
    "    ax.set_xticklabels(ax.get_xticklabels(), rotation=90, ha='center')\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "# todo save and show the plot\n",
    "plt.savefig('../../Statistical Data/Appendix/sampled-plot-all-cat.pdf')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a467812f81969935"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
